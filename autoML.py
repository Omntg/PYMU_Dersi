import pandas as pd
import numpy as np
from pycaret.classification import *
import os

# ============================================ 
# AYARLAR
# ============================================ 
CONFIG = {
    'input_file': 'ml_filtre_verileri.xlsx',
    'target_col': 'TARGET_3D',
    # 'Current_Trend' Ã§Ä±karÄ±ldÄ± Ã§Ã¼nkÃ¼ TARGET_3D ile Ã§ok yÃ¼ksek korelasyonlu (Data Leakage/Persistence)
    'ignore_cols': ['CODE', 'DATE', 'Current_Trend'], 
    'train_size': 0.8,               
    'session_id': 123,
    'log_experiment': False,
    'experiment_name': 'fintech_trend_prediction'
}

def run_pycaret_automl():
    print("="*60)
    print("ğŸš€ PYCARET AUTOML BAÅLATILIYOR (LEAKAGE FIX UYGULANDI)")
    print("="*60)

    # 1. Veriyi Oku
    print(f"\nğŸ“‚ Veri okunuyor: {CONFIG['input_file']}")
    if not os.path.exists(CONFIG['input_file']):
        print(f"âŒ HATA: Dosya bulunamadÄ±! ({CONFIG['input_file']})")
        return

    df = pd.read_excel(CONFIG['input_file'])
    print(f"âœ… Veri yÃ¼klendi. Boyut: {df.shape}")

    # ------------------------------------------------------------
    # LEAKAGE FIX 3: FormÃ¼l SÄ±zÄ±ntÄ±sÄ±nÄ± Ã–nleme (Sadece PriceAbove)
    # ------------------------------------------------------------
    # Veri setinde binary '_Slope' kolonlarÄ± bulunmuyor (sadece Slope_Rate var).
    # Ancak '_PriceAbove' (0/1) kolonlarÄ± var ve bunlar Target formÃ¼lÃ¼nÃ¼n bir parÃ§asÄ±.
    # Modelin ezber yapmasÄ±nÄ± Ã¶nlemek iÃ§in bu binary kolonlarÄ± Ã§Ä±karÄ±yoruz.
    
    leak_cols = [c for c in df.columns if c.endswith('_PriceAbove')]
    
    # Mevcut ignore listesine ekle
    current_ignore = set(CONFIG['ignore_cols'])
    current_ignore.update(leak_cols)
    CONFIG['ignore_cols'] = list(current_ignore)
    
    print(f"\nğŸš« SÄ±zÄ±ntÄ± Ã¶nlemi: {len(leak_cols)} adet '_PriceAbove' Ã¶zelliÄŸi eÄŸitimden Ã§Ä±karÄ±ldÄ±.")
    # ------------------------------------------------------------

    # Eksik verileri temizle
    df = df.dropna(subset=[CONFIG['target_col']])
    
    # Tarihe gÃ¶re sÄ±rala
    if 'DATE' in df.columns:
        df = df.sort_values('DATE')
        print("âœ… Veriler tarihe gÃ¶re sÄ±ralandÄ±.")

    # 2. PyCaret Setup
    print("\nâš™ï¸ PyCaret Setup yapÄ±lÄ±yor...")
    
    s = setup(
        data=df,
        target=CONFIG['target_col'],
        ignore_features=CONFIG['ignore_cols'],
        train_size=CONFIG['train_size'],
        data_split_shuffle=False,      
        data_split_stratify=False,
        fold_strategy='timeseries',    
        fold=3,                        
        session_id=CONFIG['session_id'],
        verbose=False,
        html=False,
        log_experiment=CONFIG['log_experiment'],
        experiment_name=CONFIG['experiment_name']
    )
    
    print("âœ… Setup tamamlandÄ±.")
    
    # 3. Modelleri KarÅŸÄ±laÅŸtÄ±r
    print("\nğŸï¸ Modeller karÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor...")
    best_models = compare_models(n_select=3, sort='F1', verbose=True)
    
    best_model = best_models[0]
    print(f"\nğŸ† En Ä°yi Model: {best_model}")

    # 4. Optimize Et
    print("\nğŸ‹ï¸ Model optimize ediliyor...")
    tuned_model = tune_model(best_model, optimize='F1', fold=3, verbose=False)
    
    # 5. SonuÃ§lar
    print("\nğŸ“Š Test Seti PerformansÄ±:")
    predict_model(tuned_model)
    
    # 6. Feature Importance
    print("\nğŸ” Feature Importance Kaydediliyor...")
    try:
        plot_model(tuned_model, plot='feature', save=True)
        print("âœ… Feature Importance.png")
        
        plot_model(tuned_model, plot='confusion_matrix', save=True)
        print("âœ… Confusion Matrix.png")
        
        # ----------------------------------------------------------
        # TÃœM FEATURE IMPORTANCE SKORLARINI DIÅARI AKTAR
        # ----------------------------------------------------------
        # Modelin kullandÄ±ÄŸÄ± tÃ¼m Ã¶zelliklerin skorlarÄ±nÄ± alÄ±p CSV'ye kaydedelim.
        # BÃ¶ylece grafikte Ã§Ä±kmayan Dist_Pct gibi Ã¶zellikleri de gÃ¶rebiliriz.
        
        # Modelin kendisini al (Pipeline iÃ§inden)
        model_obj = tuned_model
        
        # EÄŸer pipeline ise asÄ±l modeli Ã§ekmeye Ã§alÄ±ÅŸ
        if hasattr(model_obj, 'steps'):
            model_obj = model_obj.steps[-1][1]
            
        if hasattr(model_obj, 'feature_importances_'):
            # Ã–zellik isimlerini al
            feature_names = get_config('X_train').columns
            importances = model_obj.feature_importances_
            
            fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
            fi_df = fi_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)
            
            # CSV'ye kaydet
            fi_df.to_csv('feature_importance_all.csv', index=False)
            print("âœ… 'feature_importance_all.csv' olarak tÃ¼m skorlar kaydedildi.")
            
            # Ä°lk 20'yi ekrana bas
            print("\nğŸ† TOP 20 Ã–ZELLÄ°KLER:")
            print(fi_df.head(20))
            
            # Dist_Pct'lerin durumunu Ã¶zel olarak gÃ¶ster
            print("\nğŸ“‰ DISTANCE (UZAKLIK) Ã–ZELLÄ°KLERÄ°NÄ°N SIRALAMASI:")
            dist_features = fi_df[fi_df['Feature'].str.contains('Dist_Pct')]
            print(dist_features)
        else:
            print("âš ï¸ Bu model tÃ¼rÃ¼ feature_importances_ Ã¶zniteliÄŸine sahip deÄŸil.")
            
        # ----------------------------------------------------------

    except Exception as e:
        print(f"âš ï¸ Feature Importance hatasÄ±: {e}")

    # 7. Kaydet
    final_model = finalize_model(tuned_model)
    save_model(final_model, 'fintech_best_model')
    print("âœ… Model kaydedildi.")

if __name__ == "__main__":
    run_pycaret_automl()